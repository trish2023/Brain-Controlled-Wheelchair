# Brain-Controlled-Wheelchair


ğŸ§  Brain-Controlled Wheelchair â€“ EEG + Blink-Based Navigation
This repository contains the implementation of a real-time Brain-Computer Interface (BCI) system designed to help individuals with severe motor impairments control a wheelchair using only their brain signals and eye blinks.

Using EEG data from the Neiry BCI headset and blink patterns detected via OpenCV, the system interprets user intent through a combination of cognitive state classification and blink-based commands. A lightweight Decision Tree or CNN-LSTM model processes the EEG inputs, while a rule-based logic layer fuses it with blink events to issue commands such as move forward, turn left/right, or stop.

This repo includes everything from data collection and model training to real-time inference, logging, and control logic â€” all geared toward accessible, low-cost, and explainable assistive technology.

ğŸ“ Project Structure
BCI/
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ brain_data_log.csv               # Raw EEG dataset used for training
â”‚
â”œâ”€â”€ real_time_system/
â”‚   â”œâ”€â”€ __pycache__/                     # Cached Python files
â”‚   â”œâ”€â”€ data_logger/                     # Module for logging EEG and system states
â”‚   â”œâ”€â”€ logs/                            # Runtime logs for debugging
â”‚   â”œâ”€â”€ blink_detector.py                # Detects blinks using OpenCV + dlib
â”‚   â”œâ”€â”€ brain_data_log.csv               # EEG data used in real-time simulation
â”‚   â”œâ”€â”€ cnn_lstm_model.py                # CNN-LSTM model definition (for comparison)
â”‚   â”œâ”€â”€ cnn_lstm_model.cpython-313.pyc   # Compiled version of the model
â”‚   â”œâ”€â”€ control_logic.py                 # Rule-based logic combining EEG & blink inputs
â”‚   â”œâ”€â”€ eeg_inference.py                 # Live EEG classification using trained model
â”‚   â”œâ”€â”€ eeg_logger.py                    # Collects and logs EEG data in real-time
â”‚   â”œâ”€â”€ model_weights.pth                # Saved weights for the trained model
â”‚   â”œâ”€â”€ predicted_state_log.txt          # Output log of predicted mental states
â”‚   â”œâ”€â”€ shape_predictor_68_face_landmark.dat # Landmark model for blink detection
â”‚   â”œâ”€â”€ shape_predictor_68_face_landmark.zip # (Compressed version)
â”‚   â”œâ”€â”€ train_model.py                   # Script to train Decision Tree or CNN+LSTM
â”‚   â”œâ”€â”€ emo.py                           # (Optional) Emo state-related processing
â”‚   â”œâ”€â”€ pyneurosdk2-1.0.15.tar.gz        # SDK for Neiry EEG headset integration
â”‚   â””â”€â”€ requirements.txt                 # All required Python packages

ğŸ§  Control Logic
| Mental State  | Blink Type   | Action           |
| ------------- | ------------ | ---------------- |
| Focused       | Single Blink | Move Forward     |
| Focused       | Double Blink | Turn Right       |
| Focused       | Triple Blink | Turn Left        |
| Relaxed/Other | Any Input    | Stop (Safe Mode) |

